{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-vgg16.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aM2M3FppEh9B"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "rN_ME54DEemv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXy1A17DEDdT",
        "outputId": "d6e54712-ae45-4d94-9021-1e0228a2847e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "aM2M3FppEh9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "5e8cPOcCEDdU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZOC372BFKrF",
        "outputId": "349d6172-31cf-4f87-aac5-22e4e13c2f9d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.10.0+cu111\n",
            "0.11.1+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configs\n"
      ],
      "metadata": {
        "id": "faMyE26yE42a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(linewidth=130)\n",
        "torch.set_grad_enabled(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hT2W8aFEkB9",
        "outputId": "b03f091a-b02d-4604-a6fb-27f23b28ce4e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7fc902d5fbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture"
      ],
      "metadata": {
        "id": "SOealq-vFcBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyVgg16(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # Define your layers as class attributes\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv1_2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv2_2 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv3 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv3_2 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv4 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding='valid')\n",
        "    self.conv4_2 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding='valid')\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=512*7*7, out_features=4096)\n",
        "    self.fc2 = nn.Linear(in_features=4096, out_features=4096)\n",
        "    self.out = nn.Linear(in_features=4096, out_features=10)\n",
        "  \n",
        "  #implement network's forward pass in the forward() call. The __call__ will invoke the forward method.\n",
        "  def forward(self, t):\n",
        "\n",
        "    # First Block\n",
        "    t = F.relu(self.conv1(t))\n",
        "    t = F.relu(self.conv1_2(t))\n",
        "    t = F.max_pool2d(t, kernel_size=3, stride=2)\n",
        "\n",
        "    # Second Block\n",
        "    t = F.relu(self.conv2(t))\n",
        "    t = F.relu(self.conv2_2(t))\n",
        "    t = F.max_pool2d(t, kernel_size=3, stride=2)\n",
        "\n",
        "    # Third Block\n",
        "    t = F.relu(self.conv3(t))\n",
        "    t = F.relu(self.conv3_2(t))\n",
        "    t = F.relu(self.conv3_2(t))\n",
        "    t = F.max_pool2d(t, kernel_size=3, stride=2)\n",
        "\n",
        "    # Fourth Block\n",
        "    t = F.relu(self.conv4(t))\n",
        "    t = F.relu(self.conv4_2(t))\n",
        "    t = F.relu(self.conv4_2(t))\n",
        "    t = F.max_pool2d(t, kernel_size=3, stride=2)\n",
        "\n",
        "    # Flatten\n",
        "    t = t.reshape((-1, 7*7*512))\n",
        "\n",
        "    # FC 1\n",
        "    t = F.relu(self.fc1(t))\n",
        "    # FC 2\n",
        "    t = F.relu(self.fc2(t))\n",
        "    # Output\n",
        "    t = self.out(t)\n",
        "\n",
        "    return t\n",
        "\n"
      ],
      "metadata": {
        "id": "Y18DCgm9FlOY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "ZAOlKM6oIu6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FashionMNIST"
      ],
      "metadata": {
        "id": "3jSi__9OIxZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\n",
        "    root = './data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([transforms.ToTensor(), transforms.Resize(224)])\n",
        ")"
      ],
      "metadata": {
        "id": "lD4djcchI0yw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=8)"
      ],
      "metadata": {
        "id": "ZcZcVX9gKIXl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sample the Data"
      ],
      "metadata": {
        "id": "cD5cW517PExd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels = next(iter(train_loader))\n",
        "print(labels)\n",
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPb3066yPI8Z",
        "outputId": "6b92ebea-17cd-42f4-8caf-1fc8e3657f0f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9, 0, 0, 3, 0, 2, 7, 2])\n",
            "torch.Size([8, 1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train\n"
      ],
      "metadata": {
        "id": "gx4VbuuGK5Fu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate the model.\n",
        "model = MyVgg16()\n",
        "\n",
        "# Give model's parameters to optimizer. Later, when the gradients are computer,\n",
        "# they will be stored in each parameter, so the optimizer can perfofrm the step,\n",
        "# by just having access to parameters.\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "9GDBsNDhK7eA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "  \n",
        "  epoch_loss = 0\n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "\n",
        "    preds = model(images)\n",
        "    batch_loss = F.cross_entropy(preds, labels)\n",
        "\n",
        "    optimizer.zero_grad() # Because in successive iterations PyTorch will accumulate \n",
        "                          # gradient from previous steps.\n",
        "\n",
        "    batch_loss.backward() # Calculare Gradients\n",
        "    # Now we have gradients at each parameter\n",
        "    # This can be viewed by : model.conv1.weight.grad tensor\n",
        "\n",
        "    optimizer.step() # Update Weights\n",
        "    print(batch_loss)\n",
        "    epoch_loss += batch_loss\n",
        "\n",
        "  print(epoch_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VKqZkNSMuhj",
        "outputId": "c09318e2-c75e-4f81-930a-49eab2dc2d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2951, grad_fn=<NllLossBackward0>)\n",
            "tensor(4.7011e+08, grad_fn=<NllLossBackward0>)\n",
            "tensor(353.6143, grad_fn=<NllLossBackward0>)\n",
            "tensor(24.7315, grad_fn=<NllLossBackward0>)\n",
            "tensor(20438.3047, grad_fn=<NllLossBackward0>)\n",
            "tensor(2639.2219, grad_fn=<NllLossBackward0>)\n",
            "tensor(110.4575, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    }
  ]
}